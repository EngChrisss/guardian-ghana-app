# ðŸ”§ UPDATE SECTION: PollutionPredictor class in utils/prediction_engine.py
# FIND and DELETE the existing PollutionPredictor class
# REPLACE with this OPTIMIZED version:

import pandas as pd
import streamlit as st
from utils.satellite_data import get_nasa_satellite_data, get_weather_data
import numpy as np
from datetime import datetime
import time


class PollutionPredictor:
    def __init__(self):
        self.risk_thresholds = {
            'low': 0.3,
            'medium': 0.6,
            'high': 0.8
        }

        # PRE-COMPUTE hotspot data for faster access
        self.mining_hotspots = self._initialize_hotspots()
        self.hotspot_coords = np.array([[h['lat'], h['lon']] for h in self.mining_hotspots])
        self.hotspot_intensities = np.array([h['intensity'] for h in self.mining_hotspots])

        # Cache for frequently accessed data
        self._prediction_cache = {}
        self._cache_timeout = 300  # 5 minutes

    def _initialize_hotspots(self):
        """Initialize mining hotspots with optimized data structure"""
        return [
            # PRA RIVER BASIN - High intensity mining areas
            {'lat': 5.650, 'lon': -1.100, 'intensity': 0.95, 'river': 'Pra River', 'name': 'Dunkwa-on-Offin',
             'type': 'large_scale'},
            {'lat': 5.720, 'lon': -0.950, 'intensity': 0.90, 'river': 'Pra River', 'name': 'Oda River Junction',
             'type': 'medium_scale'},
            {'lat': 5.580, 'lon': -1.250, 'intensity': 0.85, 'river': 'Pra River', 'name': 'Nsuta Mining Area',
             'type': 'large_scale'},
            {'lat': 6.250, 'lon': -1.150, 'intensity': 0.92, 'river': 'Birim River', 'name': 'Akwatia Diamond Fields',
             'type': 'large_scale'},
            {'lat': 6.180, 'lon': -1.080, 'intensity': 0.88, 'river': 'Birim River', 'name': 'Kade Concessions',
             'type': 'medium_scale'},
            {'lat': 6.300, 'lon': -1.220, 'intensity': 0.80, 'river': 'Birim River', 'name': 'Asamankese Area',
             'type': 'small_scale'},
            {'lat': 5.300, 'lon': -2.350, 'intensity': 0.87, 'river': 'Ankobra River', 'name': 'Prestea Mining Zone',
             'type': 'large_scale'},
            {'lat': 5.450, 'lon': -2.450, 'intensity': 0.83, 'river': 'Ankobra River', 'name': 'Bogoso Concessions',
             'type': 'medium_scale'},
            {'lat': 5.200, 'lon': -2.280, 'intensity': 0.78, 'river': 'Ankobra River', 'name': 'Tarkwa Area',
             'type': 'large_scale'},
            {'lat': 6.200, 'lon': -1.850, 'intensity': 0.85, 'river': 'Offin River', 'name': 'Jacobu Mining Area',
             'type': 'medium_scale'},
            {'lat': 6.250, 'lon': -1.950, 'intensity': 0.82, 'river': 'Offin River', 'name': 'Bekwai Concessions',
             'type': 'small_scale'},
            {'lat': 6.350, 'lon': -2.850, 'intensity': 0.75, 'river': 'Tano River', 'name': 'Bibiani Gold Belt',
             'type': 'large_scale'},
            {'lat': 6.280, 'lon': -2.750, 'intensity': 0.70, 'river': 'Tano River', 'name': 'Sefwi Area',
             'type': 'medium_scale'},
        ]

    def predict_pollution_risk(self, latitude, longitude, river_name):
        """OPTIMIZED AI prediction with caching and faster calculations"""

        # Check cache first
        cache_key = f"{latitude:.3f}_{longitude:.3f}_{river_name}"
        current_time = time.time()

        if (cache_key in self._prediction_cache and
                current_time - self._prediction_cache[cache_key]['timestamp'] < self._cache_timeout):
            return self._prediction_cache[cache_key]['prediction']

        # Get real-time data (optimized parallel calls)
        satellite_data = get_nasa_satellite_data(latitude, longitude)
        weather_data = get_weather_data(latitude, longitude)

        # Calculate comprehensive risk score (0-100) - OPTIMIZED
        risk_score = self.calculate_comprehensive_risk_optimized(
            latitude, longitude, river_name, satellite_data, weather_data
        )

        # Determine risk level with confidence
        risk_level, confidence = self.determine_risk_level(risk_score, latitude, longitude)

        # Get nearest hotspot information (optimized)
        nearest_hotspot = self.get_nearest_hotspot_optimized(latitude, longitude)

        prediction = {
            'river_name': river_name,
            'latitude': latitude,
            'longitude': longitude,
            'risk_level': risk_level,
            'risk_score': risk_score,
            'confidence': confidence,
            'factors': self.get_risk_factors_optimized(satellite_data, weather_data, river_name, nearest_hotspot),
            'nearest_hotspot': nearest_hotspot,
            'prediction_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_sources': ['NASA Satellite', 'Weather API', 'Ghana EPA Hotspots']
        }

        # Cache the result
        self._prediction_cache[cache_key] = {
            'prediction': prediction,
            'timestamp': current_time
        }

        return prediction

    def get_nearest_hotspot_optimized(self, lat, lon):
        """OPTIMIZED: Find nearest hotspot using vectorized calculations"""
        # Convert to numpy array for faster computation
        current_coord = np.array([lat, lon])

        # Calculate distances using vectorized operations (MUCH faster)
        distances = np.sqrt(np.sum((self.hotspot_coords - current_coord) ** 2, axis=1))

        # Find minimum distance
        min_idx = np.argmin(distances)
        min_distance = distances[min_idx]

        nearest = self.mining_hotspots[min_idx].copy()
        nearest['distance_km'] = round(min_distance * 111, 2)  # Convert to kilometers

        return nearest

    def calculate_comprehensive_risk_optimized(self, lat, lon, river_name, satellite_data, weather_data):
        """OPTIMIZED risk algorithm with vectorized operations"""

        # Factor 1: Mining proximity (40% weight) - OPTIMIZED
        mining_risk = self.calculate_mining_proximity_risk_optimized(lat, lon) * 0.40

        # Factor 2: Satellite turbidity (30% weight)
        turbidity_risk = (min(satellite_data['turbidity_index'] / 150, 1)) * 0.30

        # Factor 3: Rainfall runoff (20% weight)
        rainfall_risk = (min(weather_data['rainfall'] / 30, 1)) * 0.20

        # Factor 4: Seasonal patterns (10% weight)
        seasonal_risk = self.calculate_seasonal_risk() * 0.10

        total_risk = (mining_risk + turbidity_risk + rainfall_risk + seasonal_risk) * 100

        return min(100, total_risk)

    def calculate_mining_proximity_risk_optimized(self, lat, lon):
        """OPTIMIZED: Calculate risk using vectorized distance calculations"""
        current_coord = np.array([lat, lon])

        # Vectorized distance calculation
        distances = np.sqrt(np.sum((self.hotspot_coords - current_coord) ** 2, axis=1))

        # Vectorized risk calculation
        risks = self.hotspot_intensities * np.maximum(0, 1 - (distances / 0.5))

        return np.max(risks) if len(risks) > 0 else 0

    def calculate_seasonal_risk(self):
        """Optimized seasonal risk calculation"""
        month = datetime.now().month
        # Use dictionary lookup for faster season detection
        season_risk = {
            'dry': [11, 12, 1, 2],
            'rainy': [6, 7, 8, 9],
            'transition': [3, 4, 5, 10]
        }

        if month in season_risk['dry']:
            return 0.8
        elif month in season_risk['rainy']:
            return 0.6
        else:
            return 0.7

    def determine_risk_level(self, risk_score, lat, lon):
        """Optimized risk level determination"""
        if risk_score >= 70:
            risk_level = "ðŸ”´ CRITICAL"
        elif risk_score >= 50:
            risk_level = "ðŸŸ  HIGH"
        elif risk_score >= 30:
            risk_level = "ðŸŸ¡ MEDIUM"
        else:
            risk_level = "ðŸŸ¢ LOW"

        confidence = self.calculate_confidence_optimized(lat, lon)
        return risk_level, confidence

    def calculate_confidence_optimized(self, lat, lon):
        """OPTIMIZED confidence calculation"""
        current_coord = np.array([lat, lon])
        distances = np.sqrt(np.sum((self.hotspot_coords - current_coord) ** 2, axis=1))
        min_distance = np.min(distances) if len(distances) > 0 else float('inf')

        if min_distance < 0.1:  # ~11km
            return "HIGH"
        elif min_distance < 0.3:  # ~33km
            return "MEDIUM"
        else:
            return "LOW"

    def get_risk_factors_optimized(self, satellite_data, weather_data, river_name, nearest_hotspot):
        """Optimized risk factor generation"""
        factors = []

        # Mining activity factors
        if nearest_hotspot and nearest_hotspot['distance_km'] < 50:
            factors.append(f"Near {nearest_hotspot['name']} ({nearest_hotspot['distance_km']}km)")
            factors.append(f"{nearest_hotspot['type'].replace('_', ' ').title()} mining activity")

        # Satellite factors
        if satellite_data['turbidity_index'] > 80:
            factors.append(f"High turbidity ({satellite_data['turbidity_index']:.0f} NTU)")

        if satellite_data['water_color'] != "Clear (Green-Blue)":
            factors.append(f"Water discoloration detected")

        # Weather factors
        if weather_data['rainfall'] > 20:
            factors.append(f"Heavy rainfall ({weather_data['rainfall']}mm - runoff risk)")

        # Seasonal factors
        month = datetime.now().month
        if month in [11, 12, 1, 2]:
            factors.append("Dry season - pollution concentration")

        if not factors:
            factors.append("Normal conditions - low risk")

        return factors[:4]  # Limit to top 4 factors for performance

    def generate_risk_map_data_optimized(self):
        """FIXED: Generate risk predictions with CORRECT column names"""
        risk_data = []

        # Use sparser grid for better performance
        lat_points = np.arange(4.5, 11.5, 0.5)
        lon_points = np.arange(-3.5, 1.5, 0.5)

        for lat in lat_points:
            for lon in lon_points:
                closest_river = self.find_closest_river_optimized(lat, lon)
                prediction = self.predict_pollution_risk(lat, lon, closest_river)

                risk_data.append({
                    'lat': lat,
                    'lon': lon,
                    'risk_score': prediction['risk_score'],
                    'risk_level': prediction['risk_level'],
                    'river_name': closest_river,
                    'nearest_hotspot': prediction['nearest_hotspot']['name'],
                    'hotspot_distance': prediction['nearest_hotspot']['distance_km']
                })

        # Create DataFrame and ensure proper data types
        risk_df = pd.DataFrame(risk_data)

        # CRITICAL: Ensure numeric columns are properly typed
        risk_df['lat'] = pd.to_numeric(risk_df['lat'], errors='coerce')
        risk_df['lon'] = pd.to_numeric(risk_df['lon'], errors='coerce')
        risk_df['risk_score'] = pd.to_numeric(risk_df['risk_score'], errors='coerce')
        risk_df['hotspot_distance'] = pd.to_numeric(risk_df['hotspot_distance'], errors='coerce')

        # Drop any rows with invalid coordinates
        risk_df = risk_df.dropna(subset=['lat', 'lon'])

        return risk_df

    def find_closest_river_optimized(self, lat, lon):
        """OPTIMIZED river finding using pre-computed distances"""
        rivers = [
            ("Pra River", 5.5, -1.0),
            ("Ankobra River", 5.2, -2.2),
            ("Birim River", 6.2, -1.1),
            ("Tano River", 6.3, -2.8),
            ("Offin River", 6.2, -1.9),
            ("Volta River", 7.5, 0.5)
        ]

        river_coords = np.array([[r[1], r[2]] for r in rivers])
        current_coord = np.array([lat, lon])

        distances = np.sqrt(np.sum((river_coords - current_coord) ** 2, axis=1))
        min_idx = np.argmin(distances)

        return rivers[min_idx][0]

    def generate_risk_map_data(self):
        """Legacy method for backward compatibility with app.py"""
        return self.generate_risk_map_data_optimized()

    def clear_cache(self):
        """Clear prediction cache"""
        self._prediction_cache.clear()

# Create global instance
predictor = PollutionPredictor()